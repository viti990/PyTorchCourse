{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNrmr8CWtDE4+HjW5DAwh6D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "27fc70cf364e4b7fa28f4e458bdc1715": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_84172e07c17945e6ba7e0f4e7727780c",
              "IPY_MODEL_7e8dbbb805424eb281c9e0a5de545222",
              "IPY_MODEL_e8c913a391974bb3979ec33aa12f529e"
            ],
            "layout": "IPY_MODEL_6bebcf5016bf4aeca6259a396ff3a552"
          }
        },
        "84172e07c17945e6ba7e0f4e7727780c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb20b3ed50ae45929b474830b8f5f2fb",
            "placeholder": "​",
            "style": "IPY_MODEL_ad34e4212d014fc1a4e8c0c78ccce0f0",
            "value": " 60%"
          }
        },
        "7e8dbbb805424eb281c9e0a5de545222": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25be9e9ba5554e66ad15c999f0454811",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_18d92c9eaf6c49e4b02487ccbde3dfc1",
            "value": 6
          }
        },
        "e8c913a391974bb3979ec33aa12f529e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43776c58ec2445bd86d2c482b1fff2a5",
            "placeholder": "​",
            "style": "IPY_MODEL_53b45530c21d423cb5b3a249ae747a53",
            "value": " 6/10 [17:43&lt;11:47, 176.77s/it]"
          }
        },
        "6bebcf5016bf4aeca6259a396ff3a552": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb20b3ed50ae45929b474830b8f5f2fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad34e4212d014fc1a4e8c0c78ccce0f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25be9e9ba5554e66ad15c999f0454811": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18d92c9eaf6c49e4b02487ccbde3dfc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "43776c58ec2445bd86d2c482b1fff2a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53b45530c21d423cb5b3a249ae747a53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/viti990/PyTorchCourse/blob/main/09_PyTorch_Model_Deployment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 09. Pytorch Model Deployment\n",
        "\n",
        "What is model deployment?\n",
        "\n",
        "Machine learning model deployment is the act of making you machine learning model(s) available to someone or something else."
      ],
      "metadata": {
        "id": "zHUy3X0hgsCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Get setup"
      ],
      "metadata": {
        "id": "Hq5lUKebh3TS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For this notebook to run with updated APIs, we need torch 1.12+ and torchvision 0.13+\n",
        "try:\n",
        "    import torch\n",
        "    import torchvision\n",
        "    assert int(torch.__version__.split(\".\")[1]) >= 12, \"torch version should be 1.12+\"\n",
        "    assert int(torchvision.__version__.split(\".\")[1]) >= 13, \"torchvision version should be 0.13+\"\n",
        "    print(f\"torch version: {torch.__version__}\")\n",
        "    print(f\"torchvision version: {torchvision.__version__}\")\n",
        "except:\n",
        "    print(f\"[INFO] torch/torchvision versions not as required, installing nightly versions.\")\n",
        "    !pip3 install -U torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113\n",
        "    import torch\n",
        "    import torchvision\n",
        "    print(f\"torch version: {torch.__version__}\")\n",
        "    print(f\"torchvision version: {torchvision.__version__}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JB0Ixp4OiNYK",
        "outputId": "1f833f49-36c6-4f2f-f3a9-d8563d8c8fbf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] torch/torchvision versions not as required, installing nightly versions.\n",
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu113\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.0+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n",
            "torch version: 2.3.0+cu121\n",
            "torchvision version: 0.18.0+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Continue with regular imports\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "\n",
        "# Try to get torchinfo, install it if it doesn't work\n",
        "try:\n",
        "    from torchinfo import summary\n",
        "except:\n",
        "    print(\"[INFO] Couldn't find torchinfo... installing it.\")\n",
        "    !pip install -q torchinfo\n",
        "    from torchinfo import summary\n",
        "\n",
        "# Try to import the going_modular directory, download it from GitHub if it doesn't work\n",
        "try:\n",
        "    from going_modular.going_modular import data_setup, engine\n",
        "    from helper_functions import download_data, set_seeds, plot_loss_curves\n",
        "except:\n",
        "    # Get the going_modular scripts\n",
        "    print(\"[INFO] Couldn't find going_modular or helper_functions scripts... downloading them from GitHub.\")\n",
        "    !git clone https://github.com/mrdbourke/pytorch-deep-learning\n",
        "    !mv pytorch-deep-learning/going_modular .\n",
        "    !mv pytorch-deep-learning/helper_functions.py . # get the helper_functions.py script\n",
        "    !rm -rf pytorch-deep-learning\n",
        "    from going_modular.going_modular import data_setup, engine\n",
        "    from helper_functions import download_data, set_seeds, plot_loss_curves"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0C48g_uBibYc",
        "outputId": "4812b524-9d85-42a3-f65f-f40f8285f717"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Couldn't find torchinfo... installing it.\n",
            "[INFO] Couldn't find going_modular or helper_functions scripts... downloading them from GitHub.\n",
            "Cloning into 'pytorch-deep-learning'...\n",
            "remote: Enumerating objects: 4056, done.\u001b[K\n",
            "remote: Total 4056 (delta 0), reused 0 (delta 0), pack-reused 4056\u001b[K\n",
            "Receiving objects: 100% (4056/4056), 646.90 MiB | 26.91 MiB/s, done.\n",
            "Resolving deltas: 100% (2372/2372), done.\n",
            "Updating files: 100% (248/248), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "O4S3ePFCiwYj",
        "outputId": "54306dba-fe61-4291-aa0d-b6c61d8c8879"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Getting data\n",
        "\n",
        "The dataset we're going to use for deploying a FoodVision Mini model is...\n",
        "\n",
        "Pizza, steak, sushi 20% dataset (pizza, steak, sushi classes from Food101, random 20% of samples)"
      ],
      "metadata": {
        "id": "4mDrsoQgiATL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download pizza, steak, sushi images from GitHub\n",
        "data_20_percent_path = download_data(source=\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi_20_percent.zip\",\n",
        "                                     destination=\"pizza_steak_sushi_20_percent\")\n",
        "\n",
        "data_20_percent_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Ckj1T9RidgW",
        "outputId": "cd828af2-1fe2-462e-8e80-787649e9dde4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Did not find data/pizza_steak_sushi_20_percent directory, creating one...\n",
            "[INFO] Downloading pizza_steak_sushi_20_percent.zip from https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi_20_percent.zip...\n",
            "[INFO] Unzipping pizza_steak_sushi_20_percent.zip data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('data/pizza_steak_sushi_20_percent')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup training and test paths\n",
        "train_dir = data_20_percent_path / \"train\"\n",
        "test_dir = data_20_percent_path / \"test\"\n",
        "train_dir, test_dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLGadKOpjUSR",
        "outputId": "a550a758-e4cc-4c14-f11c-ddf5c79663aa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(PosixPath('data/pizza_steak_sushi_20_percent/train'),\n",
              " PosixPath('data/pizza_steak_sushi_20_percent/test'))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. FoodVision Mini model deployment experiment outline\n",
        "\n",
        "### 3 questions:\n",
        "1. What is my most ideal machine learning model deployment scenario?\n",
        "2. Where is my model hoing to go?\n",
        "3. How is my model going to function?\n",
        "\n",
        "**FoodVision Mini ideal use case:** A model that performs well and fast.\n",
        "\n",
        "1. Performs well: 95%+ accuracy\n",
        "2. Fast: as close to real-time (or faster) as possible (30FPS+ or 30ms latency)\n",
        "  * Latency = time for prediction take place\n",
        "\n",
        "\n",
        "To try and achieve these goals, we're going to build 2 model experiments:\n",
        "1. EffNetB2 feature extractor (just like in 07. PyTorch Experiment Tracking)\n",
        "2. ViT feature extractor (just like in 08. Pytorch Paper Replicating)"
      ],
      "metadata": {
        "id": "4yzvzJqZjnMQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Creating an EffNetB2 feature extractor\n",
        "\n",
        "Feature extractor = a term for a transfer learning model that has its base layers frozen and output layers (or head layers) customized to a certain problem.\n",
        "\n",
        "EffNetB2 pretrained model in pytorch https://pytorch.org/vision/stable/models/generated/torchvision.models.efficientnet_b2.html#torchvision.models.EfficientNet_B2_Weights"
      ],
      "metadata": {
        "id": "55ViyT1Xld2c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Setup pretrained EffNetB2 weights\n",
        "effenet_b2_weights = torchvision.models.EfficientNet_B2_Weights.DEFAULT # \"DEFAULT\" is equivalent to saying \"BEST AVAILABLE\"\n",
        "\n",
        "# 2. Get EffNetB2 transform\n",
        "effnetb2_transforms = effenet_b2_weights.transforms()\n",
        "\n",
        "# 3. Setup pretrained model instance\n",
        "effnetb2 = torchvision.models.efficientnet_b2(weights=effenet_b2_weights) # could also use weights =\"DEFAULT\"\n",
        "\n",
        "# 4. Freeze the base layers in the model (this will stop all layers from training)\n",
        "for param in effnetb2.parameters():\n",
        "  param.requires_grad = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0Or1mtRlxNk",
        "outputId": "46a93013-99bd-4158-e6e0-cdcca28eca8b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b2_rwightman-c35c1473.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b2_rwightman-c35c1473.pth\n",
            "100%|██████████| 35.2M/35.2M [00:00<00:00, 75.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchinfo import summary\n",
        "\n",
        "summary(effnetb2,\n",
        "        input_size=(1,3,224,224),\n",
        "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
        "        col_width=20,\n",
        "        row_settings=[\"var_names\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECKgathpnSUA",
        "outputId": "d30f4357-d516-4881-deee-89ed330739f5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "============================================================================================================================================\n",
              "Layer (type (var_name))                                      Input Shape          Output Shape         Param #              Trainable\n",
              "============================================================================================================================================\n",
              "EfficientNet (EfficientNet)                                  [1, 3, 224, 224]     [1, 1000]            --                   False\n",
              "├─Sequential (features)                                      [1, 3, 224, 224]     [1, 1408, 7, 7]      --                   False\n",
              "│    └─Conv2dNormActivation (0)                              [1, 3, 224, 224]     [1, 32, 112, 112]    --                   False\n",
              "│    │    └─Conv2d (0)                                       [1, 3, 224, 224]     [1, 32, 112, 112]    (864)                False\n",
              "│    │    └─BatchNorm2d (1)                                  [1, 32, 112, 112]    [1, 32, 112, 112]    (64)                 False\n",
              "│    │    └─SiLU (2)                                         [1, 32, 112, 112]    [1, 32, 112, 112]    --                   --\n",
              "│    └─Sequential (1)                                        [1, 32, 112, 112]    [1, 16, 112, 112]    --                   False\n",
              "│    │    └─MBConv (0)                                       [1, 32, 112, 112]    [1, 16, 112, 112]    (1,448)              False\n",
              "│    │    └─MBConv (1)                                       [1, 16, 112, 112]    [1, 16, 112, 112]    (612)                False\n",
              "│    └─Sequential (2)                                        [1, 16, 112, 112]    [1, 24, 56, 56]      --                   False\n",
              "│    │    └─MBConv (0)                                       [1, 16, 112, 112]    [1, 24, 56, 56]      (6,004)              False\n",
              "│    │    └─MBConv (1)                                       [1, 24, 56, 56]      [1, 24, 56, 56]      (10,710)             False\n",
              "│    │    └─MBConv (2)                                       [1, 24, 56, 56]      [1, 24, 56, 56]      (10,710)             False\n",
              "│    └─Sequential (3)                                        [1, 24, 56, 56]      [1, 48, 28, 28]      --                   False\n",
              "│    │    └─MBConv (0)                                       [1, 24, 56, 56]      [1, 48, 28, 28]      (16,518)             False\n",
              "│    │    └─MBConv (1)                                       [1, 48, 28, 28]      [1, 48, 28, 28]      (43,308)             False\n",
              "│    │    └─MBConv (2)                                       [1, 48, 28, 28]      [1, 48, 28, 28]      (43,308)             False\n",
              "│    └─Sequential (4)                                        [1, 48, 28, 28]      [1, 88, 14, 14]      --                   False\n",
              "│    │    └─MBConv (0)                                       [1, 48, 28, 28]      [1, 88, 14, 14]      (50,300)             False\n",
              "│    │    └─MBConv (1)                                       [1, 88, 14, 14]      [1, 88, 14, 14]      (123,750)            False\n",
              "│    │    └─MBConv (2)                                       [1, 88, 14, 14]      [1, 88, 14, 14]      (123,750)            False\n",
              "│    │    └─MBConv (3)                                       [1, 88, 14, 14]      [1, 88, 14, 14]      (123,750)            False\n",
              "│    └─Sequential (5)                                        [1, 88, 14, 14]      [1, 120, 14, 14]     --                   False\n",
              "│    │    └─MBConv (0)                                       [1, 88, 14, 14]      [1, 120, 14, 14]     (149,158)            False\n",
              "│    │    └─MBConv (1)                                       [1, 120, 14, 14]     [1, 120, 14, 14]     (237,870)            False\n",
              "│    │    └─MBConv (2)                                       [1, 120, 14, 14]     [1, 120, 14, 14]     (237,870)            False\n",
              "│    │    └─MBConv (3)                                       [1, 120, 14, 14]     [1, 120, 14, 14]     (237,870)            False\n",
              "│    └─Sequential (6)                                        [1, 120, 14, 14]     [1, 208, 7, 7]       --                   False\n",
              "│    │    └─MBConv (0)                                       [1, 120, 14, 14]     [1, 208, 7, 7]       (301,406)            False\n",
              "│    │    └─MBConv (1)                                       [1, 208, 7, 7]       [1, 208, 7, 7]       (686,868)            False\n",
              "│    │    └─MBConv (2)                                       [1, 208, 7, 7]       [1, 208, 7, 7]       (686,868)            False\n",
              "│    │    └─MBConv (3)                                       [1, 208, 7, 7]       [1, 208, 7, 7]       (686,868)            False\n",
              "│    │    └─MBConv (4)                                       [1, 208, 7, 7]       [1, 208, 7, 7]       (686,868)            False\n",
              "│    └─Sequential (7)                                        [1, 208, 7, 7]       [1, 352, 7, 7]       --                   False\n",
              "│    │    └─MBConv (0)                                       [1, 208, 7, 7]       [1, 352, 7, 7]       (846,900)            False\n",
              "│    │    └─MBConv (1)                                       [1, 352, 7, 7]       [1, 352, 7, 7]       (1,888,920)          False\n",
              "│    └─Conv2dNormActivation (8)                              [1, 352, 7, 7]       [1, 1408, 7, 7]      --                   False\n",
              "│    │    └─Conv2d (0)                                       [1, 352, 7, 7]       [1, 1408, 7, 7]      (495,616)            False\n",
              "│    │    └─BatchNorm2d (1)                                  [1, 1408, 7, 7]      [1, 1408, 7, 7]      (2,816)              False\n",
              "│    │    └─SiLU (2)                                         [1, 1408, 7, 7]      [1, 1408, 7, 7]      --                   --\n",
              "├─AdaptiveAvgPool2d (avgpool)                                [1, 1408, 7, 7]      [1, 1408, 1, 1]      --                   --\n",
              "├─Sequential (classifier)                                    [1, 1408]            [1, 1000]            --                   False\n",
              "│    └─Dropout (0)                                           [1, 1408]            [1, 1408]            --                   --\n",
              "│    └─Linear (1)                                            [1, 1408]            [1, 1000]            (1,409,000)          False\n",
              "============================================================================================================================================\n",
              "Total params: 9,109,994\n",
              "Trainable params: 0\n",
              "Non-trainable params: 9,109,994\n",
              "Total mult-adds (M): 659.05\n",
              "============================================================================================================================================\n",
              "Input size (MB): 0.60\n",
              "Forward/backward pass size (MB): 156.81\n",
              "Params size (MB): 36.44\n",
              "Estimated Total Size (MB): 193.85\n",
              "============================================================================================================================================"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "effnetb2.classifier"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJ4Lj9nLoPTk",
        "outputId": "09caafe2-0326-4f5e-de41-1380900e40d9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Dropout(p=0.3, inplace=True)\n",
              "  (1): Linear(in_features=1408, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set seeds for reproducibility\n",
        "set_seeds()\n",
        "effnetb2.classifier = nn.Sequential(\n",
        "    nn.Dropout(p=0.3, inplace=True),\n",
        "    nn.Linear(in_features=1408, # keep in_features same\n",
        "              out_features=3) # change out features to match the number of classes\n",
        ")"
      ],
      "metadata": {
        "id": "VRW70Uoaokp1"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchinfo import summary\n",
        "\n",
        "summary(effnetb2,\n",
        "        input_size=(1,3,224,224),\n",
        "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
        "        col_width=20,\n",
        "        row_settings=[\"var_names\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmzfsa1CpLhy",
        "outputId": "21ae4959-9428-4b88-8954-8131cf9a136b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "============================================================================================================================================\n",
              "Layer (type (var_name))                                      Input Shape          Output Shape         Param #              Trainable\n",
              "============================================================================================================================================\n",
              "EfficientNet (EfficientNet)                                  [1, 3, 224, 224]     [1, 3]               --                   Partial\n",
              "├─Sequential (features)                                      [1, 3, 224, 224]     [1, 1408, 7, 7]      --                   False\n",
              "│    └─Conv2dNormActivation (0)                              [1, 3, 224, 224]     [1, 32, 112, 112]    --                   False\n",
              "│    │    └─Conv2d (0)                                       [1, 3, 224, 224]     [1, 32, 112, 112]    (864)                False\n",
              "│    │    └─BatchNorm2d (1)                                  [1, 32, 112, 112]    [1, 32, 112, 112]    (64)                 False\n",
              "│    │    └─SiLU (2)                                         [1, 32, 112, 112]    [1, 32, 112, 112]    --                   --\n",
              "│    └─Sequential (1)                                        [1, 32, 112, 112]    [1, 16, 112, 112]    --                   False\n",
              "│    │    └─MBConv (0)                                       [1, 32, 112, 112]    [1, 16, 112, 112]    (1,448)              False\n",
              "│    │    └─MBConv (1)                                       [1, 16, 112, 112]    [1, 16, 112, 112]    (612)                False\n",
              "│    └─Sequential (2)                                        [1, 16, 112, 112]    [1, 24, 56, 56]      --                   False\n",
              "│    │    └─MBConv (0)                                       [1, 16, 112, 112]    [1, 24, 56, 56]      (6,004)              False\n",
              "│    │    └─MBConv (1)                                       [1, 24, 56, 56]      [1, 24, 56, 56]      (10,710)             False\n",
              "│    │    └─MBConv (2)                                       [1, 24, 56, 56]      [1, 24, 56, 56]      (10,710)             False\n",
              "│    └─Sequential (3)                                        [1, 24, 56, 56]      [1, 48, 28, 28]      --                   False\n",
              "│    │    └─MBConv (0)                                       [1, 24, 56, 56]      [1, 48, 28, 28]      (16,518)             False\n",
              "│    │    └─MBConv (1)                                       [1, 48, 28, 28]      [1, 48, 28, 28]      (43,308)             False\n",
              "│    │    └─MBConv (2)                                       [1, 48, 28, 28]      [1, 48, 28, 28]      (43,308)             False\n",
              "│    └─Sequential (4)                                        [1, 48, 28, 28]      [1, 88, 14, 14]      --                   False\n",
              "│    │    └─MBConv (0)                                       [1, 48, 28, 28]      [1, 88, 14, 14]      (50,300)             False\n",
              "│    │    └─MBConv (1)                                       [1, 88, 14, 14]      [1, 88, 14, 14]      (123,750)            False\n",
              "│    │    └─MBConv (2)                                       [1, 88, 14, 14]      [1, 88, 14, 14]      (123,750)            False\n",
              "│    │    └─MBConv (3)                                       [1, 88, 14, 14]      [1, 88, 14, 14]      (123,750)            False\n",
              "│    └─Sequential (5)                                        [1, 88, 14, 14]      [1, 120, 14, 14]     --                   False\n",
              "│    │    └─MBConv (0)                                       [1, 88, 14, 14]      [1, 120, 14, 14]     (149,158)            False\n",
              "│    │    └─MBConv (1)                                       [1, 120, 14, 14]     [1, 120, 14, 14]     (237,870)            False\n",
              "│    │    └─MBConv (2)                                       [1, 120, 14, 14]     [1, 120, 14, 14]     (237,870)            False\n",
              "│    │    └─MBConv (3)                                       [1, 120, 14, 14]     [1, 120, 14, 14]     (237,870)            False\n",
              "│    └─Sequential (6)                                        [1, 120, 14, 14]     [1, 208, 7, 7]       --                   False\n",
              "│    │    └─MBConv (0)                                       [1, 120, 14, 14]     [1, 208, 7, 7]       (301,406)            False\n",
              "│    │    └─MBConv (1)                                       [1, 208, 7, 7]       [1, 208, 7, 7]       (686,868)            False\n",
              "│    │    └─MBConv (2)                                       [1, 208, 7, 7]       [1, 208, 7, 7]       (686,868)            False\n",
              "│    │    └─MBConv (3)                                       [1, 208, 7, 7]       [1, 208, 7, 7]       (686,868)            False\n",
              "│    │    └─MBConv (4)                                       [1, 208, 7, 7]       [1, 208, 7, 7]       (686,868)            False\n",
              "│    └─Sequential (7)                                        [1, 208, 7, 7]       [1, 352, 7, 7]       --                   False\n",
              "│    │    └─MBConv (0)                                       [1, 208, 7, 7]       [1, 352, 7, 7]       (846,900)            False\n",
              "│    │    └─MBConv (1)                                       [1, 352, 7, 7]       [1, 352, 7, 7]       (1,888,920)          False\n",
              "│    └─Conv2dNormActivation (8)                              [1, 352, 7, 7]       [1, 1408, 7, 7]      --                   False\n",
              "│    │    └─Conv2d (0)                                       [1, 352, 7, 7]       [1, 1408, 7, 7]      (495,616)            False\n",
              "│    │    └─BatchNorm2d (1)                                  [1, 1408, 7, 7]      [1, 1408, 7, 7]      (2,816)              False\n",
              "│    │    └─SiLU (2)                                         [1, 1408, 7, 7]      [1, 1408, 7, 7]      --                   --\n",
              "├─AdaptiveAvgPool2d (avgpool)                                [1, 1408, 7, 7]      [1, 1408, 1, 1]      --                   --\n",
              "├─Sequential (classifier)                                    [1, 1408]            [1, 3]               --                   True\n",
              "│    └─Dropout (0)                                           [1, 1408]            [1, 1408]            --                   --\n",
              "│    └─Linear (1)                                            [1, 1408]            [1, 3]               4,227                True\n",
              "============================================================================================================================================\n",
              "Total params: 7,705,221\n",
              "Trainable params: 4,227\n",
              "Non-trainable params: 7,700,994\n",
              "Total mult-adds (M): 657.64\n",
              "============================================================================================================================================\n",
              "Input size (MB): 0.60\n",
              "Forward/backward pass size (MB): 156.80\n",
              "Params size (MB): 30.82\n",
              "Estimated Total Size (MB): 188.22\n",
              "============================================================================================================================================"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Creating a function to make an EffNetB2 feature extractor"
      ],
      "metadata": {
        "id": "6lbQvzrT_a16"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_effnetb2_model(num_classes:int=3,\n",
        "                          seed:int=42,\n",
        "                          ):\n",
        "  # 1, 2, 3 Create EffBetB2 pretrained weights, transforms and model\n",
        "\n",
        "  weights = torchvision.models.EfficientNet_B2_Weights.DEFAULT\n",
        "  transforms = weights.transforms()\n",
        "  model = torchvision.models.efficientnet_b2(weights=weights)\n",
        "\n",
        "  # 4. Freeze all layers in the base model\n",
        "  for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "  # 5. Change classifier head with random seed for reproducibility\n",
        "  torch.manual_seed(seed)\n",
        "  model.classifier = nn.Sequential(\n",
        "      nn.Dropout(p=0.3, inplace=True),\n",
        "      nn.Linear(in_features=1408,\n",
        "                out_features=num_classes)\n",
        "  )\n",
        "\n",
        "  return model, transforms"
      ],
      "metadata": {
        "id": "fxz_upKRpLz3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "effnetb2, effnetb2_transforms = create_effnetb2_model()"
      ],
      "metadata": {
        "id": "z6R_tCvBz4HZ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(effnetb2,\n",
        "        input_size=(1,3,224,224),\n",
        "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
        "        col_width=20,\n",
        "        row_settings=[\"var_names\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6FEQyfX0FGF",
        "outputId": "bab70f78-8685-4332-8288-6a2326569a79"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "============================================================================================================================================\n",
              "Layer (type (var_name))                                      Input Shape          Output Shape         Param #              Trainable\n",
              "============================================================================================================================================\n",
              "EfficientNet (EfficientNet)                                  [1, 3, 224, 224]     [1, 3]               --                   Partial\n",
              "├─Sequential (features)                                      [1, 3, 224, 224]     [1, 1408, 7, 7]      --                   False\n",
              "│    └─Conv2dNormActivation (0)                              [1, 3, 224, 224]     [1, 32, 112, 112]    --                   False\n",
              "│    │    └─Conv2d (0)                                       [1, 3, 224, 224]     [1, 32, 112, 112]    (864)                False\n",
              "│    │    └─BatchNorm2d (1)                                  [1, 32, 112, 112]    [1, 32, 112, 112]    (64)                 False\n",
              "│    │    └─SiLU (2)                                         [1, 32, 112, 112]    [1, 32, 112, 112]    --                   --\n",
              "│    └─Sequential (1)                                        [1, 32, 112, 112]    [1, 16, 112, 112]    --                   False\n",
              "│    │    └─MBConv (0)                                       [1, 32, 112, 112]    [1, 16, 112, 112]    (1,448)              False\n",
              "│    │    └─MBConv (1)                                       [1, 16, 112, 112]    [1, 16, 112, 112]    (612)                False\n",
              "│    └─Sequential (2)                                        [1, 16, 112, 112]    [1, 24, 56, 56]      --                   False\n",
              "│    │    └─MBConv (0)                                       [1, 16, 112, 112]    [1, 24, 56, 56]      (6,004)              False\n",
              "│    │    └─MBConv (1)                                       [1, 24, 56, 56]      [1, 24, 56, 56]      (10,710)             False\n",
              "│    │    └─MBConv (2)                                       [1, 24, 56, 56]      [1, 24, 56, 56]      (10,710)             False\n",
              "│    └─Sequential (3)                                        [1, 24, 56, 56]      [1, 48, 28, 28]      --                   False\n",
              "│    │    └─MBConv (0)                                       [1, 24, 56, 56]      [1, 48, 28, 28]      (16,518)             False\n",
              "│    │    └─MBConv (1)                                       [1, 48, 28, 28]      [1, 48, 28, 28]      (43,308)             False\n",
              "│    │    └─MBConv (2)                                       [1, 48, 28, 28]      [1, 48, 28, 28]      (43,308)             False\n",
              "│    └─Sequential (4)                                        [1, 48, 28, 28]      [1, 88, 14, 14]      --                   False\n",
              "│    │    └─MBConv (0)                                       [1, 48, 28, 28]      [1, 88, 14, 14]      (50,300)             False\n",
              "│    │    └─MBConv (1)                                       [1, 88, 14, 14]      [1, 88, 14, 14]      (123,750)            False\n",
              "│    │    └─MBConv (2)                                       [1, 88, 14, 14]      [1, 88, 14, 14]      (123,750)            False\n",
              "│    │    └─MBConv (3)                                       [1, 88, 14, 14]      [1, 88, 14, 14]      (123,750)            False\n",
              "│    └─Sequential (5)                                        [1, 88, 14, 14]      [1, 120, 14, 14]     --                   False\n",
              "│    │    └─MBConv (0)                                       [1, 88, 14, 14]      [1, 120, 14, 14]     (149,158)            False\n",
              "│    │    └─MBConv (1)                                       [1, 120, 14, 14]     [1, 120, 14, 14]     (237,870)            False\n",
              "│    │    └─MBConv (2)                                       [1, 120, 14, 14]     [1, 120, 14, 14]     (237,870)            False\n",
              "│    │    └─MBConv (3)                                       [1, 120, 14, 14]     [1, 120, 14, 14]     (237,870)            False\n",
              "│    └─Sequential (6)                                        [1, 120, 14, 14]     [1, 208, 7, 7]       --                   False\n",
              "│    │    └─MBConv (0)                                       [1, 120, 14, 14]     [1, 208, 7, 7]       (301,406)            False\n",
              "│    │    └─MBConv (1)                                       [1, 208, 7, 7]       [1, 208, 7, 7]       (686,868)            False\n",
              "│    │    └─MBConv (2)                                       [1, 208, 7, 7]       [1, 208, 7, 7]       (686,868)            False\n",
              "│    │    └─MBConv (3)                                       [1, 208, 7, 7]       [1, 208, 7, 7]       (686,868)            False\n",
              "│    │    └─MBConv (4)                                       [1, 208, 7, 7]       [1, 208, 7, 7]       (686,868)            False\n",
              "│    └─Sequential (7)                                        [1, 208, 7, 7]       [1, 352, 7, 7]       --                   False\n",
              "│    │    └─MBConv (0)                                       [1, 208, 7, 7]       [1, 352, 7, 7]       (846,900)            False\n",
              "│    │    └─MBConv (1)                                       [1, 352, 7, 7]       [1, 352, 7, 7]       (1,888,920)          False\n",
              "│    └─Conv2dNormActivation (8)                              [1, 352, 7, 7]       [1, 1408, 7, 7]      --                   False\n",
              "│    │    └─Conv2d (0)                                       [1, 352, 7, 7]       [1, 1408, 7, 7]      (495,616)            False\n",
              "│    │    └─BatchNorm2d (1)                                  [1, 1408, 7, 7]      [1, 1408, 7, 7]      (2,816)              False\n",
              "│    │    └─SiLU (2)                                         [1, 1408, 7, 7]      [1, 1408, 7, 7]      --                   --\n",
              "├─AdaptiveAvgPool2d (avgpool)                                [1, 1408, 7, 7]      [1, 1408, 1, 1]      --                   --\n",
              "├─Sequential (classifier)                                    [1, 1408]            [1, 3]               --                   True\n",
              "│    └─Dropout (0)                                           [1, 1408]            [1, 1408]            --                   --\n",
              "│    └─Linear (1)                                            [1, 1408]            [1, 3]               4,227                True\n",
              "============================================================================================================================================\n",
              "Total params: 7,705,221\n",
              "Trainable params: 4,227\n",
              "Non-trainable params: 7,700,994\n",
              "Total mult-adds (M): 657.64\n",
              "============================================================================================================================================\n",
              "Input size (MB): 0.60\n",
              "Forward/backward pass size (MB): 156.80\n",
              "Params size (MB): 30.82\n",
              "Estimated Total Size (MB): 188.22\n",
              "============================================================================================================================================"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 Creating DataLoaders for EffNetB2"
      ],
      "metadata": {
        "id": "8NQodcua2CwI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup dataloader\n",
        "from going_modular.going_modular import data_setup\n",
        "\n",
        "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir=train_dir,\n",
        "                                                                   test_dir=test_dir,\n",
        "                                                                   transform=effnetb2_transforms,\n",
        "                                                                   batch_size=32\n",
        "                                                                   )"
      ],
      "metadata": {
        "id": "v4VLSpz70Ogf"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataloader), len(test_dataloader), class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmDha-5e1o5S",
        "outputId": "92838d88-285e-458e-ac62-dd4fef3e30c2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15, 5, ['pizza', 'steak', 'sushi'])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3 Training EffNetB2 feature extractor"
      ],
      "metadata": {
        "id": "GVkrByd12YOt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loss function\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "# optimizer\n",
        "optimizer = torch.optim.Adam(effnetb2.parameters(),\n",
        "                            lr=0.001)\n",
        "# training function (engine.py)\n",
        "from going_modular.going_modular import engine\n",
        "set_seeds()\n",
        "effnetb2_results = engine.train(model=effnetb2,\n",
        "                                train_dataloader=train_dataloader,\n",
        "                                test_dataloader=test_dataloader,\n",
        "                                optimizer=optimizer,\n",
        "                                epochs=10,\n",
        "                                loss_fn=loss_fn,\n",
        "                                device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "27fc70cf364e4b7fa28f4e458bdc1715",
            "84172e07c17945e6ba7e0f4e7727780c",
            "7e8dbbb805424eb281c9e0a5de545222",
            "e8c913a391974bb3979ec33aa12f529e",
            "6bebcf5016bf4aeca6259a396ff3a552",
            "fb20b3ed50ae45929b474830b8f5f2fb",
            "ad34e4212d014fc1a4e8c0c78ccce0f0",
            "25be9e9ba5554e66ad15c999f0454811",
            "18d92c9eaf6c49e4b02487ccbde3dfc1",
            "43776c58ec2445bd86d2c482b1fff2a5",
            "53b45530c21d423cb5b3a249ae747a53"
          ]
        },
        "id": "lR2QXbY32qeC",
        "outputId": "94f72a06-53a2-4984-8936-e795e404c6e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "27fc70cf364e4b7fa28f4e458bdc1715",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.9794 | train_acc: 0.5708 | test_loss: 0.7390 | test_acc: 0.9284\n",
            "Epoch: 2 | train_loss: 0.6835 | train_acc: 0.8771 | test_loss: 0.5929 | test_acc: 0.9347\n",
            "Epoch: 3 | train_loss: 0.5640 | train_acc: 0.8958 | test_loss: 0.4816 | test_acc: 0.9409\n",
            "Epoch: 4 | train_loss: 0.4716 | train_acc: 0.8729 | test_loss: 0.4183 | test_acc: 0.9597\n",
            "Epoch: 5 | train_loss: 0.4308 | train_acc: 0.8729 | test_loss: 0.3723 | test_acc: 0.9659\n",
            "Epoch: 6 | train_loss: 0.3738 | train_acc: 0.8979 | test_loss: 0.3456 | test_acc: 0.9506\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.4 Inspecting EffNetB2 loss curves"
      ],
      "metadata": {
        "id": "9DZ6_7etDMrC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from helper_functions import plot_loss_curves\n",
        "\n",
        "plot_loss_curves(effnetb2_results)"
      ],
      "metadata": {
        "id": "IY_C02MFD1to"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.5 Saving EffNetB2 feature extractor"
      ],
      "metadata": {
        "id": "I89DniSHEFcL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from going_modular.going_modular import utils\n",
        "\n",
        "# save the model\n",
        "utils.save_model(model=effnetb2,\n",
        "                 target_dir=\"models\",\n",
        "                 model_names=\"09_pretrained_effnetb2_feature_extractor_pizza_steak_sushi_20_percent.pth\")"
      ],
      "metadata": {
        "id": "jz-_IkS3EriF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.6 Inspecting the size of our EffNetb2 feature extractor\n",
        "\n",
        "Why would it be important to consider the size of a saved model?\n",
        "\n",
        "If we're deploying our model to be used on a mobile app/website, there may be limited compute resources.\n",
        "\n",
        "So if our model file is too large, we may not be able to store/run it on our target device."
      ],
      "metadata": {
        "id": "OyUQsDTOFFj2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# Get the model size in bytes and convert to megabytes\n",
        "pretrained_effnetb2_model_size = Path(\"models\\09_pretrained_effnetb2_feature_extractor_pizza_steak_sushi_20_percent.pth\").stat().st_size()\n",
        "print(f\"Pretrained EffNetB2 fearure extractor size: {round(pretrained_effnetb2_model_size/(1024*1024),2)} MB\")"
      ],
      "metadata": {
        "id": "WxaRRe2xFNZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.7 Collecting EffNetB2 features extractor stats"
      ],
      "metadata": {
        "id": "SFZyTRELGhS7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count number of parameters in EffNetB2\n",
        "effnetb2_total_params = sum(torch.numel(param) for param in effnetb2.parameters())\n",
        "effnetb2_total_params"
      ],
      "metadata": {
        "id": "wodmJp7WHSwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dictionary with EffNetB2 statistics\n",
        "effnetb2_stats = {\"test_loss\": effnetb2_results[\"test_loss\"][-1],\n",
        "                  \"test_acc\": effnetb2_results[\"test_acc\"][-1],\n",
        "                  \"number_of_parameters\": effnetb2_total_params,\n",
        "                  \"model_size (MB)\": pretrained_effnetb2_model_size}\n",
        "effnetb2_stats"
      ],
      "metadata": {
        "id": "Abs0vEeJHmXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Creating a ViT feature extractor\n",
        "\n",
        "We're up to our second modelling experiment, repeating the steps fot EffNetB2 but this time with a ViT feature extractor..."
      ],
      "metadata": {
        "id": "2TQSYgFwIr9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check out the ViT heads layer\n",
        "vit = torchvision.models.vit_b_16\n",
        "vit.heads()"
      ],
      "metadata": {
        "id": "xvIh3XvTJBYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_vit_model(num_classes:int=3,\n",
        "                     seed:int=42):\n",
        "  # Create ViT_B_16 pretrained weights, transforms and model\n",
        "  weights = torchvision.models.ViT_B_16_Weights.DEFAULT\n",
        "  transforms = weights.transforms()\n",
        "  model = torchvision.models.vit_b_16(weights=weights)\n",
        "\n",
        "  # freeze all of the base layers\n",
        "  for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "  # Change classifier head to suit our needs\n",
        "  torch.manual_seed(seed)\n",
        "  model.heads = nn.Sequential(nn.Linear(in_features=768,\n",
        "                                       out_features=num_classes))\n",
        "\n",
        "  return model, transforms"
      ],
      "metadata": {
        "id": "KfIBTg8VM5n2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vit, vit_transforms = create_vit_model()\n",
        "vit_transforms"
      ],
      "metadata": {
        "id": "yx0SUZJUNwro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(vit,\n",
        "        input_size=(1,3,224,224),\n",
        "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
        "        col_width=20,\n",
        "        row_settings=[\"var_names\"])"
      ],
      "metadata": {
        "id": "ECZDW8TXN3qn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1 Create DataLoaders for ViT feature extractor"
      ],
      "metadata": {
        "id": "U7As4ih6N9B-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# setup ViT DataLoaders\n",
        "from going_modular.going_modular import data_setup\n",
        "train_dataloader_vit, test_dataloader_vit, class_names = data_setup.create_dataloaders(train_dir=train_dir,\n",
        "                                                                                       test_dir=test_dir,\n",
        "                                                                                       transform=vit_transforms,\n",
        "                                                                                       batch_size=32)\n",
        "len(train_dataloader_vit), len(test_dataloader_vit), len(class_names)"
      ],
      "metadata": {
        "id": "GtLI3yLnPosk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2 Training a ViT Feature extractor\n",
        "\n",
        "We're up to model experiment number two: a ViT feature extractor."
      ],
      "metadata": {
        "id": "pEnXtLbXQL-_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup optimizer\n",
        "optimizer = torch.optim.Adam(vit.parameters(),\n",
        "                             lr=1e-3)\n",
        "# Setup loss function\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "# Train ViT feature extractor with seeds set for reproducibility\n",
        "set_seeds()\n",
        "vit_results = engine.train(model=vit,\n",
        "                           train_dataloader=train_dataloader_vit,\n",
        "                           test_dataloader-test_dataloader_vit,\n",
        "                           optimizer=optimizer,\n",
        "                           loss_fn=loss_fn,\n",
        "                           epochs=10,\n",
        "                           device=device)"
      ],
      "metadata": {
        "id": "qT7eyACySyh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3 Plot loss curves of ViT feature extractor"
      ],
      "metadata": {
        "id": "dj6a0MjJTcUd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_curves(vit_results)"
      ],
      "metadata": {
        "id": "1vxIkdBAT_Il"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.4 Saving ViT feature extractor"
      ],
      "metadata": {
        "id": "XjixJvzzUFh3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model\n",
        "utils.save_model(model=vit,\n",
        "                 target_dir=\"models\",\n",
        "                 model_names=\"09_pretrained_vit_feature_extractor_pizza_steak_sushi_20_percent.pth\")"
      ],
      "metadata": {
        "id": "Pd_SYsqWUi1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.5 Checking the size of ViT feature extractor"
      ],
      "metadata": {
        "id": "N9U_8hDMUw1J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# Get the model size in bytes then convert to megabytes\n",
        "pretrained_vit_model_size = Path(\"models\\09_pretrained_vit_feature_extractor_pizza_steak_sushi_20_percent.pth\").stat().st_size\n",
        "print(f\"Pretrained ViT feature extractor model size: {round(pretrained_vit_model_size/(1024*1024),2)} MB\")"
      ],
      "metadata": {
        "id": "G2ZC4Ms5U2q_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.6 Collecting ViT feature extractor stats"
      ],
      "metadata": {
        "id": "lqlJUWC4VS3S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count number of parameters in ViT\n",
        "vit_total_params = sum(torch.numel(param) for param in vit.parameters())\n",
        "vit_total_params"
      ],
      "metadata": {
        "id": "IlBjjpbTVh-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "effnetb2_total_params"
      ],
      "metadata": {
        "id": "uA96DA3mV54k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create ViT statistics dictionary\n",
        "vit_stats = {\"test_loss\": vit_results[\"test_loss\"][-1],\n",
        "             \"test_acc\": vit_results[\"test_acc\"][-1],\n",
        "             \"number_of_parameters\": vit_total_params,\n",
        "             \"Model_size (MB)\": pretrained_vit_model_size}\n",
        "vit_stats"
      ],
      "metadata": {
        "id": "JRnLqt_HV8qA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Making predictions with our trained models and timing them\n",
        "\n",
        "Our goal:\n",
        "\n",
        "1. Performs well (95%+ test accuracy)\n",
        "2. Fast (30+ FPS)\n",
        "\n",
        "To test criteria two:\n",
        "1. Loop through test images\n",
        "2. Time how long each model takes to mae a prediction on the image\n",
        "\n",
        "Let's work towards making a function called `pred_and_store()` to do so.\n",
        "\n",
        "First we'll need a list of test image paths."
      ],
      "metadata": {
        "id": "Wb1sBZjnWkRY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# Get all test data paths\n",
        "test_data_paths = list(Path(test_dir).glob(\"*/*.jpg\"))\n",
        "test_data_paths[:5]"
      ],
      "metadata": {
        "id": "c2wMmZ1yXhs5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.1 Creating a function to make across the test dataset\n",
        "\n",
        "Steps to create `pred_and_store()`:\n",
        "\n",
        "1. Create a function that takes a list of paths, a trained PyTorch model, a series of transforms (to prepare images), a list of target class names and a target device.\n",
        "2. Create an empty list to store prediction dictionaries (we want the function to return a list of dictionaries, one for each prediction).\n",
        "3. Loop through the target input paths (steps 4-14 will happen inside the loop).\n",
        "4. Create an empty dictionary for each iteration in the loop to store prediction values per sample.\n",
        "5. Get the sample path and ground truth class name (we can do this by infering the class from the path).\n",
        "6. Start the prediction timer using Python's timeit.default_timer().\n",
        "7. Open the image using `PIL.Image.open(path)`.\n",
        "8. Transform the image so it's capable of being used with the target model as well as add a batch dimension and send the image to the target device.\n",
        "9. Prepare the model for inference by sending it to the target device and turning on `eval()` mode.\n",
        "10. Turn on `torch.inference_mode()` and pass the target transformed image to the model and calculate the prediction probability using torch.softmax() and the target label using torch.argmax().\n",
        "11. Add the prediction probability and prediction class to the prediction dictionary created in step 4. Also make sure the prediction probability is on the CPU so it can be used with non-GPU libraries such as NumPy and pandas for later inspection.\n",
        "12. End the prediction timer started in step 6 and add the time to the prediction dictionary created in step 4.\n",
        "13. See if the predicted class matches the ground truth class from step 5 and add the result to the prediction dictionary created in step 4.\n",
        "14. Append the updated prediction dictionary to the empty list of predictions created in step 2.\n",
        "15. Return the list of prediction dictionaries."
      ],
      "metadata": {
        "id": "pPhBIcB9Xy0H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Dict\n",
        "def pred_and_store() -> List[dict]:"
      ],
      "metadata": {
        "id": "OWRW9epVce1A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}